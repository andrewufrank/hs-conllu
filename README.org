#+TITLE: hs-conllu

  this package provides a validating parser of the [[http://universaldependencies.org/format.html][CoNLL-U format]],
  along with a data model for its constituents.

  further processing utilities are being developed, and currently
  include tree building and processing functions, relation extraction,
  and tree linearization.

* installation
  #+BEGIN_SRC sh
  cd /path/of/choice/
  git clone $REPO_URL
  #+END_SRC
  - using =cabal=:
    #+BEGIN_SRC sh
    cabal install
    #+END_SRC
  - using =stack=:
    #+BEGIN_SRC sh
    stack setup
    stack build
    stack install --system-ghc
    #+END_SRC

  if you have problems with the dependency versions, you may try to
  alter them in the cabal file for the version you have. the version
  bounds were generated automatically by cabal, and are probably
  conservative -- the library probably will probably still work if you
  have the same major version. (if it does, make a PR!)

  if you don't want to have this kind of problem anymore, try [[https://docs.haskellstack.org/en/stable/README/][stack]]
  (see why [[https://www.fpcomplete.com/blog/2015/06/why-is-stack-not-cabal][here]]).

* usage
   if you would like to request features, please open an issue.

** Reading CoNLL-U files
   the reading functions are in the reader module.
   #+BEGIN_SRC sh
   $ ghci
   > import Conllu.IO
   > d <- readConllu "path/to/conllu"
   #+END_SRC
   will read the file at the specified path, or all the =*.conllu=
   files in that path.

   if your conllu files don't stricly follow the specification or I
   got the parser wrong, you may want to take a look at the parser
   module.

** Customizable parsers
   if you just want to tweak how a few fields of the CoNLL-U format
   are parsed, you may write a parser for that field and then
   customize your the standard parser with the =parseC= function and
   the =customC= record (defined in the parse module), using the
   overriding technique described [[https://web.archive.org/web/*/http://neilmitchell.blogspot.com.br/2008/04/optional-parameters-in-haskell.html][here]]. you then use the =read*With=
   functions in the reader module, providing your customized parser.

   I didn't make the parser as customizable as it could be, so if that
   bothers you create and issue or file a PR, please!

** Pretty-Printing
   the printing functions are in the =Print= module.
   #+BEGIN_SRC haskell
   printDoc :: Document -> String
   #+END_SRC
   is probably the only one you will need. running
   #+BEGIN_SRC sh
   runghc IO.hs 1.conllu 2.conllu ...
   #+END_SRC
   will parse and print the files to standard output. you can use the
   =diff= utility to check if there are any differences, but the only
   ones should be in removing wrong spacing -- any others would
   probably make the parser raise an exception. if not, open an issue
   to let me know!
** correcting CoNLL-U files with a lexicon
   sometimes a parser will tag names incorrectly. this can be wrong
   HEAD assignments, wrong DEPREL assignments, or it might have other
   tokens in the sentence pointing to a token in a name where would
   like it to have it pointing to the HEAD of the name.
   
   this feature will read a list of names, will search for them in
   input CoNLL-U documents, and will make a few corrections. names are
   corrected as follows: all tokens in a name are made to point to the
   HEAD of the name with =flat:name= as DEPREL, unless their DEPREL is
   one of =case=, =nmod=, =punct=, in which case they are not
   touched. moreover, any token in the sentence pointing to a token in
   the name will be made to point to the name's HEAD.

   this might not fit into everyone's wishes and languages, so I'd
   like suggestions on how to generalize this module.

*** usage
    you will need:
    - a lexicon :: a text file with a name on every line, with spaces
                   separating the tokens: "Companhia de Águas, Energia
                   e Algo" -> "Companhia de Águas , Energia e Algo"
    - a tokenization list :: this is a text file with a word to be
         tokenized on every line. the first token is the word, the
         rest is its components, all separated by spaces, as in:
         "vámonos vamos nos"
    #+BEGIN_SRC sh
      # compile script
      runghc Lexicon.hs tokenizations.txt output-dir/ lexicon.txt 1.conllu 2.conllu ...
    #+END_SRC
    this will write corrected files to the =output-dir= (if you
    specify the same directory as the files are in, they will be
    overwritten -- don't do that).

* contributing
  I'm a new haskeller, so any help will probably be useful -- even if
  its just a few pointers and comments on how I can improve the
  library or my code.

  if you want to contribute code, let me know, and go right on. you
  may want to look at the =TODO.org= file.
